#test to try and scrape data from twitter 2.0
from __future__ import print_function
import tweepy
import config
import datetime
import re
import json
import os
import pytz
import google.oauth2.credentials
import os.path

from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from googleapiclient.errors import HttpError
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build

api_key = config.api_key
api_secrets = config.api_key_secret
access_token = config.access_token
access_secret = config.access_token_secret

#
# variables
#



#
# twitter stuff
#

# Authenticate to Twitter
auth = tweepy.OAuthHandler(api_key,api_secrets)
auth.set_access_token(access_token,access_secret)
api = tweepy.API(auth)

#filter through fetched tweets and return a list of tweets associated with events
#NEED: time, name, description
#RETURN a tuple, the first variable is the tweet object, the second variable is the time in timestamp form of the event (may need to convert to timestamp form)
# FILTER METHODS to implement: keyword search, hashtag analysis, link detection, Natural Language Processing, Image/multimedia analysis

#TODO: implement computer vision / multimedia and image processing to find time/date

def filter_tweets(tweets):
    event_tweets = []
    potential_event_tweets = []

    #bank generated by AI chatGPT
    keyword_search_bank = ['Seminar', 'Workshop', 'Training', 'Summit', 'Expo', 'Festival', 'Concert', 'Webinar', 'Meetup', 'Trade show', 'Networking event', 'Charity event', 'Fundraiser', 'Product launch', 'Panel discussion', 'Keynote', 'Exhibition', 'Eventbrite', 'Meetup', 'Eventful', 'Ticketmaster', 'Cvent', 'Eventzilla', 'EventPro', 'EventGeek', 'EventMobi', 'Eventdex', 'EventHQ', 'Eventzilla']
    
    #find tweets containing keywords
    for tweet in tweets:
        for keyword in keyword_search_bank:
            if tweet.text.find(keyword) != -1:
                event_time = extract_time(tweet)
                potential_event_tweets.append([tweet, event_time])

                print(tweet.text)
                print(event_time)
                print(keyword)
                break
    
    #temp
    event_tweets = potential_event_tweets

    return event_tweets

#extract the infered or explicit time from the extracted text of a tweet
def extract_time(tweet):

    text = tweet.text
    extracted_time = 0
    time = None
    date = None
    # Regular expression pattern to match common date formats like 'next Thu', 'next Thursday', 'Thu', 'Thursday', etc.
    date_pattern = r"(next\s+)?(Mon|Tue|Wed|Thu|Fri|Sat|Sun)(day)?"

    # Regular expression pattern to match common time formats like '9 AM', '9:30 pm', '12:45', etc.
    time_pattern = r"([01]?\d|2[0-3])(:[0-5]\d)?(\s?[ap]m)?"

    # Search for date and time patterns in the text
    date_match = re.search(date_pattern, text, re.IGNORECASE)
    time_match = re.search(time_pattern, text, re.IGNORECASE)

    # Extract the date and time strings
    date_string = date_match.group() if date_match else None
    time_string = time_match.group() if time_match else None

    # Determine the reference date for 'next' cases
    reference_date = tweet.created_at
    #reference_date = datetime.datetime.now().date()

    # Mapping of weekday abbreviations to corresponding weekdays
    weekday_mapping = {
        'Mon': 0,
        'Tue': 1,
        'Wed': 2,
        'Thu': 3,
        'Fri': 4,
        'Sat': 5,
        'Sun': 6
    }

    # Parse the date and time strings into datetime objects
    if date_string:
        if "next" in date_string.lower():
            weekday = date_string.split()[1].capitalize()
            current_weekday = reference_date.weekday()
            days_ahead = (7 - (current_weekday - weekday_mapping[weekday])) % 7
            date = reference_date + datetime.timedelta(days=days_ahead)
        else:
            weekday = date_string.split()[0].capitalize()
            date = reference_date + datetime.timedelta(days=(weekday_mapping[weekday] - reference_date.weekday()) % 7)


    if time_string:
        time = datetime.datetime.strptime(time_string, "%I:%M %p") if ":" in time_string else datetime.strptime(time_string, "%I %p")

    # Print the inferred date and time
    if date:
        print("Inferred Date:", date.strftime("%Y-%m-%d"))
    if time:
        print("Inferred Time:", time.strftime("%H:%M"))

    extracted_time = [date, time]
    return extracted_time

def fetch_latest_tweets(hashtag, count):
    #user = api.get_user(screen_name='SinaiGenetics')
    #sinaifollowers = user.followers_count
    #followers = []
    #for tweet in tweepy.Cursor(api.search_tweets, q='#genechat', count=10).items():
    #    followers.append(tweet.user.followers_count)
    #    pass

    tweets = []
    numtweets = 0
    for tweet in tweepy.Cursor(api.search_tweets, q=hashtag, count=count).items():
        tweets.append(tweet)
        numtweets += 1
        #print(numtweets)
        if numtweets == count:
            return tweets
    return tweets
#
# Google Calander API stuff
#

SCOPES = ['https://www.googleapis.com/auth/calendar']
CALENDAR_ID = 'q87rr6mmge25582ulj40rkg76s@group.calendar.google.com'

def get_calendar_service():
    creds = None
    if os.path.exists('token.json'):
        creds = google.oauth2.credentials.Credentials.from_authorized_user_file('token.json', SCOPES)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(r'C:\Users\mrm028\coding\twitterGC\tests\credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        with open('token.json', 'w') as token:
            token.write(creds.to_json())
    return build('calendar', 'v3', credentials=creds)

def callo():
    creds = None
    # The file token.json stores the user's access and refresh tokens, and is
    # created automatically when the authorization flow completes for the first
    # time.
    if os.path.exists('token.json'):
        creds = google.oauth2.credentials.Credentials.from_authorized_user_file('token.json', SCOPES)
    # If there are no (valid) credentials available, let the user log in.
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                r'C:\Users\mrm028\coding\twitterGC\tests\credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        # Save the credentials for the next run
        with open('token.json', 'w') as token:
            token.write(creds.to_json())

    try:
        service = build('calendar', 'v3', credentials=creds)

        # Call the Calendar API
        now = datetime.datetime.utcnow().isoformat() + 'Z'  # 'Z' indicates UTC time
        print('Getting the upcoming 10 events')
        events_result = service.events().list(calendarId='q87rr6mmge25582ulj40rkg76s@group.calendar.google.com', timeMin=now,
                                                maxResults=10, singleEvents=True,
                                                orderBy='startTime').execute()
        events = events_result.get('items', [])

        if not events:
            print('No upcoming events found.')
            return

        # Prints the start and name of the next 10 events
        for event in events:
            start = event['start'].get('dateTime', event['start'].get('date'))
            print(start, event['summary'])

    except HttpError as error:
        print('An error occurred: %s' % error)


def create_calendar_event(service, summary, description, start_time, end_time):
    event = {
        'summary': summary,
        'description': description,
        'start': {
            'dateTime': start_time.strftime('%Y-%m-%dT%H:%M:%S'),
            'timeZone': 'UTC',
        },
        'end': {
            'dateTime': end_time.strftime('%Y-%m-%dT%H:%M:%S'),
            'timeZone': 'UTC',
        },
    }
    event = service.events().insert(calendarId=CALENDAR_ID, body=event).execute()
    print(f"Event created: {event.get('htmlLink')}")

# Fetch latest tweets and create calendar events
def fetch_tweets_and_create_events(hashtag, count):
    tweets = fetch_latest_tweets(hashtag, count)
    service = get_calendar_service()
    
    for tweet in tweets:
        tweet_text = tweet.text
        tweet_time = tweet.created_at
        tweet_user = tweet.user.name
        start_time = tweet_time - datetime.timedelta(minutes=15)
        end_time = tweet_time + datetime.timedelta(minutes=15)
        create_calendar_event(service, tweet_user, tweet_text, start_time, end_time)
        

def record_tweet_id(tweet_id):
    with open(r'C:\Users\mrm028\coding\twitterGC\tests\tweet_ids.txt', "a") as file:
        file.write(tweet_id + "\n")

def check_tweet_id_in_file(tweet_id):
    with open(r'C:\Users\mrm028\coding\twitterGC\tests\tweet_ids.txt', "r") as file:
        for line in file:
            if line.strip() == tweet_id:
                return True
    return False

#function to run on daily basis updating all events on calendar
def daily_GC_events():
   
    #number of tweets to return per hashtag
    count = 10

    #hashtags generated by AI chatGPT
    current_year = datetime.datetime.now().year
    hashtag_search_bank = ['Genechat', '#GeneticCounseling', '#GeneticCounselor', '#GeneticCounselingEvent', '#GCEvent', '#GCConference', '#GCSeminar', '#GCWorkshop', '#GCCEU', '#NSGC', '#ACGC', '#ASHG', '#EJHG', f'#ASHG{current_year}', f'#NSGC{current_year}', '#GeneticTesting', '#GenomicMedicine', '#PrecisionMedicine', '#PersonalizedMedicine', '#RareDisease', '#PrecisionHealth', '#Pharmacogenomics', '#BreastCancerGeneticCounseling', '#HuntingtonsRiskAssessment', '#CysticFibrosisGeneTesting', '#GeneticCounselingPrograms', '#GCStudent', '#GCEducation', '#GCCE']
    
    #get tweets based on hashtags and add to tweets list
    tweets = []
    for hashtag in hashtag_search_bank:
        t = fetch_latest_tweets(hashtag, count)
        for tweet in t:
            tweets.append(tweet)

 
    #get calendar service
    service = get_calendar_service()

    #filter and extract tweets associated with events
    #filter so that each tweet has an event start time associated with it as a tuple
    #first part of tuple is the tweet
    #second part of tuple is another tuple with date as first part and time as second
    event_tweets = filter_tweets(tweets)
 
    print(len(hashtag_search_bank))
    print(len(tweets))
    print(len(event_tweets))
    
    for tweet in event_tweets:
        tweet_id = tweet[0].id_str
        if (check_tweet_id_in_file(tweet_id) == False):
            record_tweet_id(tweet_id)
           
            #input event processing
            if (tweet[1][0] == None and tweet[1][1] == None):
                continue
            elif (tweet[1][0] != None and tweet[1][1] == None):
                #TODO
                tweet_text = tweet[0].text
                tweet_time = tweet[1][0]
                tweet_user = tweet[0].user.name
                start_time = tweet_time
                end_time = start_time + datetime.timedelta(minutes=30)
                create_calendar_event(service, tweet_user, tweet_text, start_time, end_time)
            elif (tweet[1][0] != None and tweet[1][1] != None):
                tweet_text = tweet[0].text
                tweet_time = tweet[0].created_at
                tweet_user = tweet[0].user.name
                start_time = datetime.datetime.combine(tweet[1][0].date(), tweet[1][1].time())
                end_time = start_time + datetime.timedelta(minutes=30)
                create_calendar_event(service, tweet_user, tweet_text, start_time, end_time)
        else:
            continue


    #temp for analyzing filter tweets
    return 0

    #post tweets to calendar
    for tweet in event_tweets:
        
        tweet_text = tweet[0].text
        tweet_time = tweet.created_at
        tweet_user = tweet.user.name
        start_time = tweet[1]
        end_time = start_time + datetime.timedelta(minutes=15)
        #create_calendar_event(service, tweet_user, tweet_text, start_time, end_time)



#token_file_path = os.path.abspath('token.json')
#print(token_file_path)
#callo()
daily_GC_events()
#print(os.path.exists('token.json'))
#fetch_tweets_and_create_events('genechat', 2)
#c = fetch_latest_tweets('genechat', 2)
#print (len(c))


###

###